import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import os
import joblib
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier
from sklearn.ensemble import VotingClassifier, StackingClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
import shap
import platform
import pickle
import time
import plotly.express as px
import plotly.graph_objects as go

# í•œê¸€ í°íŠ¸ ì„¤ì •
system_os = platform.system()

if system_os == "Windows":
    # ìœˆë„ìš°ì˜ ê²½ìš° ë§‘ì€ ê³ ë”• í°íŠ¸ ì‚¬ìš©
    plt.rc('font', family='Malgun Gothic')
elif system_os == "Darwin":
    # macOSì˜ ê²½ìš° ì• í”Œê³ ë”• í°íŠ¸ ì‚¬ìš©
    plt.rc('font', family='AppleGothic')
else:
    # ë¦¬ëˆ…ìŠ¤ ë“± ê¸°íƒ€ OSì˜ ê²½ìš° 
    try:
        # ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì‚¬ìš© ì‹œë„
        plt.rc('font', family='NanumGothic')
    except:
        # ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ í™•ì¸
        fonts = fm.findSystemFonts()
        korean_fonts = [f for f in fonts if 'Gothic' in f or 'Batang' in f or 'Gulim' in f or 'Dotum' in f]
        if korean_fonts:
            plt.rc('font', family=fm.FontProperties(fname=korean_fonts[0]).get_name())
        else:
            st.warning("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ì—ì„œ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ê·¸ë˜í”„ì—ì„œ ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ê°€ ê¹¨ì§€ëŠ” ê²ƒì„ ë°©ì§€
plt.rc('axes', unicode_minus=False)

st.set_page_config(
    page_title="ëª¨ë¸ í•™ìŠµ",
    page_icon="ğŸ§ ",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
        text-align: center;
        background: linear-gradient(to right, #1E88E5, #42A5F5);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        padding: 1rem 0;
    }
    
    .sub-header {
        font-size: 1.8rem;
        color: #0D47A1;
        margin: 1.5rem 0 1rem 0;
    }
    
    .info-text {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1E88E5;
        margin: 1rem 0;
    }
    
    .card {
        padding: 1.5rem;
        border-radius: 0.7rem;
        background-color: #f8f9fa;
        box-shadow: 0 0.25rem 0.75rem rgba(0, 0, 0, 0.1);
        margin: 1rem 0;
    }
    
    .model-card {
        background-color: white;
        padding: 1.5rem;
        border-radius: 0.7rem;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        margin: 1.5rem 0;
        border-top: 4px solid #1E88E5;
    }
    
    .metric-box {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 10px;
        text-align: center;
        background-color: #f5f9ff;
    }
    
    .metric-value {
        font-size: 1.5rem;
        font-weight: bold;
        color: #1E88E5;
    }
    
    .metric-label {
        font-size: 0.85rem;
        color: #616161;
        margin-top: 5px;
    }
    
    /* ì• ë‹ˆë©”ì´ì…˜ í—¤ë” */
    @keyframes gradientAnimation {
        0% {background-position: 0% 50%;}
        50% {background-position: 100% 50%;}
        100% {background-position: 0% 50%;}
    }
    
    .animated-header {
        font-size: 2.5rem;
        font-weight: bold;
        background: linear-gradient(270deg, #1E88E5, #1565C0, #0D47A1);
        background-size: 600% 600%;
        animation: gradientAnimation 6s ease infinite;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ì• ë‹ˆë©”ì´ì…˜ í—¤ë”
st.markdown("<div class='animated-header'>ğŸ§  ëª¨ë¸ í•™ìŠµ</div>", unsafe_allow_html=True)
st.markdown("<div class='info-text'>ì´ í˜ì´ì§€ì—ì„œëŠ” ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)

# ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
st.markdown("<h2 class='section-header'>1. ë°ì´í„° ì¤€ë¹„</h2>", unsafe_allow_html=True)

with st.container():
    st.markdown("<div class='card'>", unsafe_allow_html=True)
    
    try:
        # ë°ì´í„° ë¡œë“œ ì• ë‹ˆë©”ì´ì…˜
        data_load_state = st.text('ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”© ì¤‘...')
        
        if not os.path.exists('data/processed_data.pkl'):
            st.markdown("<div class='warning-box'>âš ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë°ì´í„° ì „ì²˜ë¦¬' í˜ì´ì§€ì—ì„œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.</div>", unsafe_allow_html=True)
            
            # ê°„ë‹¨í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±í•˜ì—¬ ê³„ì† ì§„í–‰
            st.markdown("<div class='info-text'>ìƒ˜í”Œ ë°ì´í„°ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists('data'):
                os.makedirs('data')
                
            # ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
            if not os.path.exists('models'):
                os.makedirs('models')
            
            # ê°„ë‹¨í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            n_samples = 100
            n_features = 10
            X_sample = np.random.rand(n_samples, n_features)
            y_sample = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])
            
            feature_names = [f'feature_{i}' for i in range(n_features)]
            categorical_cols = [f'feature_{i}' for i in range(3)]
            numerical_cols = [f'feature_{i}' for i in range(3, n_features)]
            
            processed_data = {
                'X_preprocessed': X_sample,
                'X': pd.DataFrame(X_sample, columns=feature_names),
                'y': pd.Series(y_sample),
                'feature_names': feature_names,
                'categorical_cols': categorical_cols,
                'numerical_cols': numerical_cols
            }
            
            # ìƒ˜í”Œ ë°ì´í„° ì €ì¥
            with open('data/processed_data.pkl', 'wb') as f:
                pickle.dump(processed_data, f)
                
            data_load_state.markdown("<div class='success-box'>âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!</div>", unsafe_allow_html=True)
        else:
            with open('data/processed_data.pkl', 'rb') as f:
                with st.spinner('ë°ì´í„° ë¡œë”© ì¤‘...'):
                    time.sleep(0.5)  # ë¡œë”© íš¨ê³¼ë¥¼ ìœ„í•œ ì§€ì—°
                    processed_data = pickle.load(f)
                
            data_load_state.markdown("<div class='success-box'>âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!</div>", unsafe_allow_html=True)
            
            # ë°ì´í„° ì •ë³´ í‘œì‹œ
            X_preprocessed = processed_data['X_preprocessed']
            y = processed_data['y']
            feature_names = processed_data['feature_names']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ğŸ“Š ë°ì´í„° í˜•íƒœ:**")
                st.markdown(f"<div class='info-text'>ìƒ˜í”Œ ìˆ˜: {X_preprocessed.shape[0]:,}<br>íŠ¹ì„± ìˆ˜: {X_preprocessed.shape[1]:,}</div>", unsafe_allow_html=True)
            
            with col2:
                st.markdown("**ğŸ¯ í´ë˜ìŠ¤ ë¶„í¬:**")
                class_counts = pd.Series(y).value_counts()
                st.markdown(f"<div class='info-text'>ì´íƒˆ(1): {class_counts.get(1, 0):,}ê°œ ({class_counts.get(1, 0)/len(y)*100:.1f}%)<br>ìœ ì§€(0): {class_counts.get(0, 0):,}ê°œ ({class_counts.get(0, 0)/len(y)*100:.1f}%)</div>", unsafe_allow_html=True)
            
            with col3:
                st.markdown("**âš™ï¸ ì „ì²˜ë¦¬ ì •ë³´:**")
                st.markdown(f"<div class='info-text'>ë²”ì£¼í˜• ë³€ìˆ˜: {len(processed_data['categorical_cols'])}ê°œ<br>ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(processed_data['numerical_cols'])}ê°œ</div>", unsafe_allow_html=True)
            
            # ì‹œê°í™” - í´ë˜ìŠ¤ ë¶„í¬
            fig = px.pie(
                values=class_counts.values, 
                names=['ê³ ê° ìœ ì§€', 'ê³ ê° ì´íƒˆ'], 
                title='í´ë˜ìŠ¤ ë¶„í¬',
                color_discrete_sequence=['#66bb6a', '#ef5350'],
                hole=0.4
            )
            
            fig.update_layout(
                legend_title='í´ë˜ìŠ¤',
                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ë°ì´í„° ë¶„í•  ì„¹ì…˜
            st.markdown("**ğŸ”„ ë°ì´í„° ë¶„í• :**")
            
            test_size = st.slider('í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨:', min_value=0.1, max_value=0.5, value=0.2, step=0.05, format='%.2f')
            random_state = st.number_input('ëœë¤ ì‹œë“œ:', min_value=0, max_value=1000, value=42)
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_preprocessed, y, test_size=test_size, random_state=random_state, stratify=y
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("<div class='info-text'>ğŸ” í•™ìŠµ ë°ì´í„° í¬ê¸°:</div>", unsafe_allow_html=True)
                st.write(f"X_train: {X_train.shape}, y_train: {len(y_train)}")
            
            with col2:
                st.markdown("<div class='info-text'>ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°:</div>", unsafe_allow_html=True)
                st.write(f"X_test: {X_test.shape}, y_test: {len(y_test)}")
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
            train_test_data = {
                'X_train': X_train,
                'X_test': X_test,
                'y_train': y_train,
                'y_test': y_test,
                'feature_names': feature_names
            }
            
            with open('data/train_test_data.pkl', 'wb') as f:
                pickle.dump(train_test_data, f)
            
            st.markdown("<div class='success-box'>âœ… í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  ì™„ë£Œ!</div>", unsafe_allow_html=True)
    
    except Exception as e:
        st.error(f"ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    st.markdown("</div>", unsafe_allow_html=True)

# ëª¨ë¸ í•™ìŠµ ì„¹ì…˜
st.markdown("<h2 class='section-header'>2. ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ</h2>", unsafe_allow_html=True)

with st.container():
    st.markdown("<div class='card'>", unsafe_allow_html=True)
    
    # ëª¨ë¸ í•™ìŠµì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    if not os.path.exists('data/train_test_data.pkl'):
        st.markdown("<div class='warning-box'>âš ï¸ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.</div>", unsafe_allow_html=True)
    else:
        try:
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
            with open('data/train_test_data.pkl', 'rb') as f:
                train_test_data = pickle.load(f)
            
            X_train = train_test_data['X_train']
            X_test = train_test_data['X_test']
            y_train = train_test_data['y_train']
            y_test = train_test_data['y_test']
            
            # ëª¨ë¸ê³¼ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
            models = {}
            results = {}
            
            # ëª¨ë¸ ì„ íƒ í¼
            st.markdown("<div class='info-text'>ğŸ“Š í•™ìŠµí•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”. ì—¬ëŸ¬ ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            # ëª¨ë¸ ì„ íƒ íƒ­ ìƒì„±
            model_tabs = st.tabs(["ê¸°ë³¸ ëª¨ë¸", "ë¶€ìŠ¤íŒ… ëª¨ë¸", "ì•™ìƒë¸” ëª¨ë¸", "ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬"])
            
            # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ íƒ­
            with model_tabs[0]:
                st.subheader("ê¸°ë³¸ ë¶„ë¥˜ ëª¨ë¸")
                
                # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ ì˜µì…˜
                col1, col2 = st.columns(2)
                with col1:
                    use_rf = st.checkbox("ëœë¤ í¬ë ˆìŠ¤íŠ¸ (RandomForest)", value=True)
                    use_lr = st.checkbox("ë¡œì§€ìŠ¤í‹± íšŒê·€ (LogisticRegression)")
                
                with col2:
                    use_svm = st.checkbox("ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  (SVM)")

                # ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
                if not any([use_rf, use_lr, use_svm]):
                    st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    use_rf = True  # ê¸°ë³¸ê°’ìœ¼ë¡œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì„¤ì •
                    st.info("ê¸°ë³¸ì ìœ¼ë¡œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ëœë¤ í¬ë ˆìŠ¤íŠ¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
                if use_rf:
                    st.markdown("##### ëœë¤ í¬ë ˆìŠ¤íŠ¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°")
                    rf_n_estimators = st.slider("RF: íŠ¸ë¦¬ ê°œìˆ˜", 10, 200, 100, 10)
                    rf_max_depth = st.slider("RF: ìµœëŒ€ ê¹Šì´", 2, 20, 10, 1)
                
                use_svm = st.checkbox("SVM(Support Vector Machine)", value=False)
                if use_svm:
                    svm_C = st.slider("SVM: ê·œì œ ê°•ë„(C)", 0.1, 10.0, 1.0, 0.1, format="%.2f")
                    svm_kernel = st.selectbox("SVM: ì»¤ë„ í•¨ìˆ˜", ['linear', 'rbf', 'poly'])
                    svm_probability = st.checkbox("SVM: í™•ë¥  ì˜ˆì¸¡ í™œì„±í™”", value=True)
            
            # ë¶€ìŠ¤íŒ… ëª¨ë¸ ì„ íƒ íƒ­
            with model_tabs[1]:
                col1, col2 = st.columns(2)
                
                with col1:
                    use_gb = st.checkbox("ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…", value=False)
                    if use_gb:
                        gb_n_estimators = st.slider("GB: íŠ¸ë¦¬ ê°œìˆ˜", 10, 200, 100, 10)
                        gb_learning_rate = st.slider("GB: í•™ìŠµë¥ ", 0.01, 0.3, 0.1, 0.01, format="%.2f")
                    
                    use_hgb = st.checkbox("íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…", value=False)
                    if use_hgb:
                        hgb_max_iter = st.slider("HGB: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜", 10, 500, 100, 10)
                        hgb_learning_rate = st.slider("HGB: í•™ìŠµë¥ ", 0.01, 0.3, 0.1, 0.01, format="%.2f")
                
                with col2:
                    use_xgb = st.checkbox("XGBoost", value=False)
                    if use_xgb:
                        xgb_n_estimators = st.slider("XGB: íŠ¸ë¦¬ ê°œìˆ˜", 10, 200, 100, 10)
                        xgb_learning_rate = st.slider("XGB: í•™ìŠµë¥ ", 0.01, 0.3, 0.1, 0.01, format="%.2f")
                        xgb_max_depth = st.slider("XGB: ìµœëŒ€ ê¹Šì´", 3, 10, 6, 1)
                    
                    use_lgbm = st.checkbox("LightGBM", value=False)
                    if use_lgbm:
                        lgbm_n_estimators = st.slider("LGBM: íŠ¸ë¦¬ ê°œìˆ˜", 10, 200, 100, 10)
                        lgbm_learning_rate = st.slider("LGBM: í•™ìŠµë¥ ", 0.01, 0.3, 0.1, 0.01, format="%.2f")
                        lgbm_num_leaves = st.slider("LGBM: ì ë…¸ë“œ ìˆ˜", 10, 100, 31, 1)
            
            # ì•™ìƒë¸” ëª¨ë¸ ì„ íƒ íƒ­
            with model_tabs[2]:
                use_voting = st.checkbox("ë³´íŒ… ì•™ìƒë¸” (Voting)", value=False)
                if use_voting:
                    voting_estimators = st.multiselect(
                        "ë³´íŒ…ì— ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë¸ ì„ íƒ:",
                        ["RandomForest", "LogisticRegression", "SVM", "GradientBoosting", "XGBoost", "LightGBM"],
                        default=["RandomForest", "LogisticRegression", "GradientBoosting"]
                    )
                    voting_type = st.radio("ë³´íŒ… ë°©ì‹:", ["hard", "soft"], index=1, 
                                        help="hard: ë‹¤ìˆ˜ê²° íˆ¬í‘œ, soft: ê° ë¶„ë¥˜ê¸°ì˜ í™•ë¥  í‰ê·  (softê°€ ì¼ë°˜ì ìœ¼ë¡œ ë” ì¢‹ìŒ)")
                
                use_stacking = st.checkbox("ìŠ¤íƒœí‚¹ ì•™ìƒë¸” (Stacking)", value=False)
                if use_stacking:
                    stacking_estimators = st.multiselect(
                        "ìŠ¤íƒœí‚¹ì˜ ê¸°ë³¸ ëª¨ë¸ ì„ íƒ:",
                        ["RandomForest", "LogisticRegression", "SVM", "GradientBoosting", "XGBoost", "LightGBM"],
                        default=["RandomForest", "GradientBoosting", "LogisticRegression"]
                    )
                    stacking_final = st.selectbox(
                        "ìŠ¤íƒœí‚¹ì˜ ìµœì¢… ëª¨ë¸ ì„ íƒ:",
                        ["LogisticRegression", "RandomForest", "GradientBoosting"],
                        index=0
                    )
            
            # ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ íƒ­
            with model_tabs[3]:
                handle_imbalance = st.checkbox("ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ ì ìš©", value=False)
                if handle_imbalance:
                    imbalance_method = st.radio(
                        "ë¶ˆê· í˜• ì²˜ë¦¬ ë°©ë²•:",
                        ["SMOTE", "ëœë¤ ì˜¤ë²„ìƒ˜í”Œë§", "ëœë¤ ì–¸ë”ìƒ˜í”Œë§"],
                        index=0,
                        help="SMOTE: ì†Œìˆ˜ í´ë˜ìŠ¤ í•©ì„±, ì˜¤ë²„ìƒ˜í”Œë§: ì†Œìˆ˜ í´ë˜ìŠ¤ ë³µì œ, ì–¸ë”ìƒ˜í”Œë§: ë‹¤ìˆ˜ í´ë˜ìŠ¤ ì œê±°"
                    )
                    
                    if imbalance_method == "SMOTE":
                        smote_k = st.slider("SMOTE: ìµœê·¼ì ‘ ì´ì›ƒ ìˆ˜(k)", 1, 10, 5, 1)
                    
                    st.info("ì„ íƒí•œ ë¶ˆê· í˜• ì²˜ë¦¬ ë°©ë²•ì´ í•™ìŠµ ë°ì´í„°ì— ì ìš©ë©ë‹ˆë‹¤.")
            
            # í•™ìŠµ ë²„íŠ¼
            if st.button("ëª¨ë¸ í•™ìŠµ ì‹œì‘", key="train_button"):
                # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë° ìƒíƒœ í…ìŠ¤íŠ¸ ì¤€ë¹„
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ ì ìš©
                X_train_processed = X_train.copy()
                y_train_processed = y_train.copy()
                
                if handle_imbalance:
                    status_text.text("ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ ì¤‘...")
                    
                    try:
                        if imbalance_method == "SMOTE":
                            smote = SMOTE(random_state=42, k_neighbors=smote_k)
                            X_train_processed, y_train_processed = smote.fit_resample(X_train, y_train)
                            st.info(f"SMOTE ì ìš© ê²°ê³¼: {pd.Series(y_train_processed).value_counts().to_dict()}")
                        
                        elif imbalance_method == "ëœë¤ ì˜¤ë²„ìƒ˜í”Œë§":
                            ros = RandomOverSampler(random_state=42)
                            X_train_processed, y_train_processed = ros.fit_resample(X_train, y_train)
                            st.info(f"ëœë¤ ì˜¤ë²„ìƒ˜í”Œë§ ì ìš© ê²°ê³¼: {pd.Series(y_train_processed).value_counts().to_dict()}")
                        
                        elif imbalance_method == "ëœë¤ ì–¸ë”ìƒ˜í”Œë§":
                            rus = RandomUnderSampler(random_state=42)
                            X_train_processed, y_train_processed = rus.fit_resample(X_train, y_train)
                            st.info(f"ëœë¤ ì–¸ë”ìƒ˜í”Œë§ ì ìš© ê²°ê³¼: {pd.Series(y_train_processed).value_counts().to_dict()}")
                    
                    except Exception as e:
                        st.error(f"ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.warning("ë¶ˆê· í˜• ì²˜ë¦¬ë¥¼ ê±´ë„ˆë›°ê³  ì›ë³¸ ë°ì´í„°ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                
                # ëª¨ë¸ ê°œìˆ˜ ê³„ì‚°
                total_models = sum([
                    use_rf, use_lr, use_svm, use_gb, use_hgb, use_xgb, use_lgbm, 
                    use_voting, use_stacking
                ])
                
                if total_models == 0:
                    st.error("ìµœì†Œí•œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤!")
                    # ê¸°ë³¸ì ìœ¼ë¡œ RandomForest ì„ íƒ
                    use_rf = True
                    rf_n_estimators = 100
                    rf_max_depth = 10
                    st.info("ê¸°ë³¸ ëª¨ë¸ë¡œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ê°€ ìë™ìœ¼ë¡œ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
                    total_models = 1  # ëª¨ë¸ ìˆ˜ ì—…ë°ì´íŠ¸
                
                progress_step = 1.0 / total_models
                progress_value = 0.0
                
                # ê°œë³„ ëª¨ë¸ í•™ìŠµ
                # ëœë¤ í¬ë ˆìŠ¤íŠ¸
                if use_rf:
                    status_text.text("ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    rf_model = RandomForestClassifier(
                        n_estimators=rf_n_estimators,
                        max_depth=rf_max_depth,
                        random_state=42,
                        n_jobs=-1
                    )
                    
                    with st.spinner('ëœë¤ í¬ë ˆìŠ¤íŠ¸ í•™ìŠµ ì¤‘...'):
                        rf_model.fit(X_train_processed, y_train_processed)
                    
                    models['RandomForest'] = rf_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # ë¡œì§€ìŠ¤í‹± íšŒê·€
                if use_lr:
                    status_text.text("ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    lr_model = LogisticRegression(
                        C=lr_C,
                        solver=lr_solver,
                        random_state=42,
                        max_iter=1000
                    )
                    
                    with st.spinner('ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ ì¤‘...'):
                        lr_model.fit(X_train_processed, y_train_processed)
                    
                    models['LogisticRegression'] = lr_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # SVM
                if use_svm:
                    status_text.text("SVM ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    svm_model = SVC(
                        C=svm_C,
                        kernel=svm_kernel,
                        probability=svm_probability,
                        random_state=42
                    )
                    
                    with st.spinner('SVM í•™ìŠµ ì¤‘...'):
                        svm_model.fit(X_train_processed, y_train_processed)
                    
                    models['SVM'] = svm_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…
                if use_gb:
                    status_text.text("ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    gb_model = GradientBoostingClassifier(
                        n_estimators=gb_n_estimators,
                        learning_rate=gb_learning_rate,
                        random_state=42
                    )
                    
                    with st.spinner('ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… í•™ìŠµ ì¤‘...'):
                        gb_model.fit(X_train_processed, y_train_processed)
                    
                    models['GradientBoosting'] = gb_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…
                if use_hgb:
                    status_text.text("íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    hgb_model = HistGradientBoostingClassifier(
                        max_iter=hgb_max_iter,
                        learning_rate=hgb_learning_rate,
                        random_state=42
                    )
                    
                    with st.spinner('íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… í•™ìŠµ ì¤‘...'):
                        hgb_model.fit(X_train_processed, y_train_processed)
                    
                    models['HistGradientBoosting'] = hgb_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # XGBoost
                if use_xgb:
                    status_text.text("XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    xgb_model = XGBClassifier(
                        n_estimators=xgb_n_estimators,
                        learning_rate=xgb_learning_rate,
                        max_depth=xgb_max_depth,
                        random_state=42,
                        use_label_encoder=False,
                        eval_metric='logloss'
                    )
                    
                    with st.spinner('XGBoost í•™ìŠµ ì¤‘...'):
                        xgb_model.fit(X_train_processed, y_train_processed)
                    
                    models['XGBoost'] = xgb_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # LightGBM
                if use_lgbm:
                    status_text.text("LightGBM ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    lgbm_model = LGBMClassifier(
                        n_estimators=lgbm_n_estimators,
                        learning_rate=lgbm_learning_rate,
                        num_leaves=lgbm_num_leaves,
                        random_state=42
                    )
                    
                    with st.spinner('LightGBM í•™ìŠµ ì¤‘...'):
                        lgbm_model.fit(X_train_processed, y_train_processed)
                    
                    models['LightGBM'] = lgbm_model
                    progress_value += progress_step
                    progress_bar.progress(progress_value)
                
                # ë³´íŒ… ì•™ìƒë¸”
                if use_voting:
                    status_text.text("ë³´íŒ… ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± ì¤‘...")
                    
                    # ì„ íƒëœ ê¸°ë³¸ ëª¨ë¸ë“¤ì´ ì‹¤ì œë¡œ í•™ìŠµë˜ì—ˆëŠ”ì§€ í™•ì¸
                    available_models = list(models.keys())
                    valid_estimators = []
                    for model_name in voting_estimators:
                        if model_name in available_models:
                            valid_estimators.append((model_name, models[model_name]))
                        else:
                            st.warning(f"{model_name} ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•„ ì•™ìƒë¸”ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                    
                    # ìœ íš¨í•œ ëª¨ë¸ì´ ìµœì†Œ 2ê°œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸
                    if len(valid_estimators) < 2:
                        st.error("ë³´íŒ… ì•™ìƒë¸”ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                        # ê¸°ë³¸ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
                        if 'RandomForest' not in models and use_rf == False:
                            st.info("ê¸°ë³¸ ëª¨ë¸(RandomForest)ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
                            rf_model = RandomForestClassifier(
                                n_estimators=100,
                                max_depth=10,
                                random_state=42,
                                n_jobs=-1
                            )
                            rf_model.fit(X_train_processed, y_train_processed)
                            models['RandomForest'] = rf_model
                            valid_estimators.append(('RandomForest', rf_model))
                        
                        # ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ì¶”ê°€
                        if 'LogisticRegression' not in models and use_lr == False:
                            st.info("ê¸°ë³¸ ëª¨ë¸(LogisticRegression)ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
                            lr_model = LogisticRegression(
                                C=1.0,
                                solver='lbfgs',
                                random_state=42,
                                max_iter=1000
                            )
                            lr_model.fit(X_train_processed, y_train_processed)
                            models['LogisticRegression'] = lr_model
                            valid_estimators.append(('LogisticRegression', lr_model))
                    
                    if len(valid_estimators) >= 2:
                        voting_model = VotingClassifier(
                            estimators=valid_estimators,
                            voting=voting_type
                        )
                        
                        with st.spinner('ë³´íŒ… ì•™ìƒë¸” í•™ìŠµ ì¤‘...'):
                            voting_model.fit(X_train_processed, y_train_processed)
                        
                        models['Voting'] = voting_model
                        progress_value += progress_step
                        progress_bar.progress(progress_value)
                    else:
                        st.error("ìœ íš¨í•œ ëª¨ë¸ì´ ë¶€ì¡±í•˜ì—¬ ë³´íŒ… ì•™ìƒë¸”ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                
                # ìŠ¤íƒœí‚¹ ì•™ìƒë¸”
                if use_stacking:
                    status_text.text("ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± ì¤‘...")
                    
                    # ì„ íƒëœ ê¸°ë³¸ ëª¨ë¸ë“¤ì´ ì‹¤ì œë¡œ í•™ìŠµë˜ì—ˆëŠ”ì§€ í™•ì¸
                    available_models = list(models.keys())
                    valid_estimators = []
                    for model_name in stacking_estimators:
                        if model_name in available_models:
                            valid_estimators.append((model_name, models[model_name]))
                        else:
                            st.warning(f"{model_name} ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•„ ìŠ¤íƒœí‚¹ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                    
                    # ìœ íš¨í•œ ëª¨ë¸ì´ ìµœì†Œ 2ê°œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸
                    if len(valid_estimators) < 2:
                        st.error("ìŠ¤íƒœí‚¹ ì•™ìƒë¸”ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                        # ê¸°ë³¸ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
                        if 'RandomForest' not in models and use_rf == False:
                            st.info("ê¸°ë³¸ ëª¨ë¸(RandomForest)ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
                            rf_model = RandomForestClassifier(
                                n_estimators=100,
                                max_depth=10,
                                random_state=42,
                                n_jobs=-1
                            )
                            rf_model.fit(X_train_processed, y_train_processed)
                            models['RandomForest'] = rf_model
                            valid_estimators.append(('RandomForest', rf_model))
                        
                        # ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ì¶”ê°€
                        if 'LogisticRegression' not in models and use_lr == False:
                            st.info("ê¸°ë³¸ ëª¨ë¸(LogisticRegression)ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
                            lr_model = LogisticRegression(
                                C=1.0,
                                solver='lbfgs',
                                random_state=42,
                                max_iter=1000
                            )
                            lr_model.fit(X_train_processed, y_train_processed)
                            models['LogisticRegression'] = lr_model
                            valid_estimators.append(('LogisticRegression', lr_model))
                    
                    # ìµœì¢… ë©”íƒ€ ëª¨ë¸ í™•ì¸
                    if stacking_final in available_models or stacking_final in [est[0] for est in valid_estimators]:
                        if stacking_final == "LogisticRegression" and "LogisticRegression" not in available_models:
                            final_estimator = LogisticRegression(C=1.0, random_state=42)
                        elif stacking_final == "RandomForest" and "RandomForest" not in available_models:
                            final_estimator = RandomForestClassifier(n_estimators=50, random_state=42)
                        elif stacking_final == "GradientBoosting" and "GradientBoosting" not in available_models:
                            final_estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)
                        else:
                            final_estimator = models.get(stacking_final, LogisticRegression(C=1.0, random_state=42))
                    else:
                        st.warning(f"{stacking_final} ëª¨ë¸ì´ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ LogisticRegressionìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                        final_estimator = LogisticRegression(C=1.0, random_state=42)
                    
                    if len(valid_estimators) >= 2:
                        try:
                            stacking_model = StackingClassifier(
                                estimators=valid_estimators,
                                final_estimator=final_estimator,
                                cv=5,
                                n_jobs=-1
                            )
                            
                            with st.spinner('ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í•™ìŠµ ì¤‘...'):
                                stacking_model.fit(X_train_processed, y_train_processed)
                            
                            models['Stacking'] = stacking_model
                            progress_value += progress_step
                            progress_bar.progress(progress_value)
                        except Exception as e:
                            st.error(f"ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    else:
                        st.error("ìœ íš¨í•œ ëª¨ë¸ì´ ë¶€ì¡±í•˜ì—¬ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            
                # ëª¨ë¸ í‰ê°€
                status_text.text("ëª¨ë¸ í‰ê°€ ì¤‘...")
                
                for model_name, model in models.items():
                    # ì˜ˆì¸¡
                    y_pred = model.predict(X_test)
                    y_prob = model.predict_proba(X_test)[:, 1]
                    
                    # í‰ê°€ ì§€í‘œ ê³„ì‚°
                    accuracy = accuracy_score(y_test, y_pred)
                    precision = precision_score(y_test, y_pred)
                    recall = recall_score(y_test, y_pred)
                    f1 = f1_score(y_test, y_pred)
                    roc_auc = roc_auc_score(y_test, y_prob)
                    
                    results[model_name] = {
                        'model': model,
                        'y_pred': y_pred,
                        'y_prob': y_prob,
                        'accuracy': accuracy,
                        'precision': precision,
                        'recall': recall,
                        'f1': f1,
                        'roc_auc': roc_auc
                    }
            
                # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸
                if not os.path.exists('models'):
                    os.makedirs('models')
                
                # ëª¨ë¸ ì €ì¥
                with open('models/trained_models.pkl', 'wb') as f:
                    pickle.dump(models, f)
                
                # ê¸°ì¡´ ëª¨ë¸ ê²°ê³¼ì™€ í˜„ì¬ ê²°ê³¼ í•©ì¹˜ê¸°
                existing_results = {}
                if os.path.exists('models/all_model_results.pkl'):
                    try:
                        with open('models/all_model_results.pkl', 'rb') as f:
                            existing_results = pickle.load(f)
                    except Exception as e:
                        st.warning(f"ê¸°ì¡´ ëª¨ë¸ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                
                # ìƒˆ ê²°ê³¼ë¥¼ ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•© (ê°™ì€ ëª¨ë¸ ì´ë¦„ì´ë©´ ìƒˆ ê²°ê³¼ë¡œ ë®ì–´ì”€)
                combined_results = {**existing_results, **results}
                
                # ê²°ê³¼ ì €ì¥
                with open('models/model_results.pkl', 'wb') as f:
                    pickle.dump(combined_results, f)
                
                # 4í˜ì´ì§€ì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ê²°ê³¼ ì •ë³´ ì €ì¥
                with open('models/all_model_results.pkl', 'wb') as f:
                    pickle.dump(combined_results, f)
                
                status_text.markdown("<div class='success-box'>âœ… ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ!</div>", unsafe_allow_html=True)
                
                # ê²°ê³¼ í‘œì‹œ
                st.markdown("### ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
                
                # í‘œ í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ëª¨ë¸ ê²°ê³¼ í‘œì‹œ (ê¸°ì¡´ ëª¨ë¸ í¬í•¨)
                result_df = pd.DataFrame({
                    'ëª¨ë¸': list(combined_results.keys()),
                    'ì •í™•ë„': [res['accuracy'] for res in combined_results.values()],
                    'ì •ë°€ë„': [res['precision'] for res in combined_results.values()],
                    'ì¬í˜„ìœ¨': [res['recall'] for res in combined_results.values()],
                    'F1 ì ìˆ˜': [res['f1'] for res in combined_results.values()],
                    'ROC AUC': [res['roc_auc'] for res in combined_results.values()]
                })
                
                # CSVë¡œ ì €ì¥
                result_df.to_csv('models/model_results.csv', index=False)
                
                st.dataframe(result_df.style.highlight_max(axis=0, subset=['ì •í™•ë„', 'ì •ë°€ë„', 'ì¬í˜„ìœ¨', 'F1 ì ìˆ˜', 'ROC AUC']), use_container_width=True)
                
                # ê° ëª¨ë¸ì— ëŒ€í•œ ìƒì„¸ ê²°ê³¼ í‘œì‹œ
                for model_name, result in combined_results.items():
                    st.markdown(f"<div class='model-card'>", unsafe_allow_html=True)
                    st.markdown(f"#### ğŸ“ˆ {model_name} ëª¨ë¸ ì„±ëŠ¥")
                    
                    col1, col2, col3, col4, col5 = st.columns(5)
                    
                    with col1:
                        st.markdown(f"<div class='metric-box'><div class='metric-value'>{result['accuracy']:.3f}</div><div class='metric-label'>ì •í™•ë„</div></div>", unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"<div class='metric-box'><div class='metric-value'>{result['precision']:.3f}</div><div class='metric-label'>ì •ë°€ë„</div></div>", unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown(f"<div class='metric-box'><div class='metric-value'>{result['recall']:.3f}</div><div class='metric-label'>ì¬í˜„ìœ¨</div></div>", unsafe_allow_html=True)
                    
                    with col4:
                        st.markdown(f"<div class='metric-box'><div class='metric-value'>{result['f1']:.3f}</div><div class='metric-label'>F1 ì ìˆ˜</div></div>", unsafe_allow_html=True)
                    
                    with col5:
                        st.markdown(f"<div class='metric-box'><div class='metric-value'>{result['roc_auc']:.3f}</div><div class='metric-label'>ROC AUC</div></div>", unsafe_allow_html=True)
                    
                    # í˜¼ë™ í–‰ë ¬ ë° ROC ê³¡ì„ 
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # í˜¼ë™ í–‰ë ¬
                        cm = confusion_matrix(y_test, result['y_pred'])
                        fig, ax = plt.subplots(figsize=(5, 4))
                        sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=ax)
                        ax.set_xlabel('ì˜ˆì¸¡')
                        ax.set_ylabel('ì‹¤ì œ')
                        ax.set_title('í˜¼ë™ í–‰ë ¬')
                        st.pyplot(fig)
                    
                    with col2:
                        # ROC ê³¡ì„ 
                        fpr, tpr, _ = roc_curve(y_test, result['y_prob'])
                        fig = px.area(
                            x=fpr, y=tpr,
                            title=f'ROC ê³¡ì„  (AUC = {result["roc_auc"]:.3f})',
                            labels=dict(x='False Positive Rate', y='True Positive Rate'),
                            width=500, height=300
                        )
                        fig.add_shape(
                            type='line', line=dict(dash='dash'),
                            x0=0, x1=1, y0=0, y1=1
                        )
                        fig.update_layout(template='plotly_white')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    st.markdown("</div>", unsafe_allow_html=True)
                
                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
                best_model_name = result_df.iloc[result_df['F1 ì ìˆ˜'].argmax()]['ëª¨ë¸']
                best_model = models[best_model_name]
                
                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                with open('models/best_model.pkl', 'wb') as f:
                    pickle.dump({
                        'model': best_model,
                        'model_name': best_model_name
                    }, f)
                
                # ì¶”ê°€ - X_processed í¬ê¸°ë¥¼ í™•ì¸í•˜ì—¬ feature_names.csv ì—…ë°ì´íŠ¸
                if hasattr(X_train_processed, 'shape'):
                    num_features = X_train_processed.shape[1]
                    # íŠ¹ì„± ì´ë¦„ íŒŒì¼ ìƒì„± (í•­ìƒ ìƒˆë¡œ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •)
                    new_feature_names = []
                    if 'feature_names' in train_test_data and train_test_data['feature_names'] is not None:
                        # ì›ë³¸ íŠ¹ì„± ì´ë¦„ì´ ìˆëŠ” ê²½ìš° ì‚¬ìš©
                        feature_list = train_test_data['feature_names']
                        if len(feature_list) == num_features:
                            new_feature_names = feature_list
                        else:
                            # íŠ¹ì„± ìˆ˜ê°€ ë‹¤ë¥´ë©´ ìƒˆë¡œ ìƒì„±
                            new_feature_names = [f'feature_{i}' for i in range(num_features)]
                    else:
                        # íŠ¹ì„± ì´ë¦„ì´ ì—†ëŠ” ê²½ìš° ìƒˆë¡œ ìƒì„±
                        new_feature_names = [f'feature_{i}' for i in range(num_features)]
                    
                    # í•­ìƒ models ë””ë ‰í† ë¦¬ì— feature_names.csv íŒŒì¼ ì €ì¥
                    if not os.path.exists('models'):
                        os.makedirs('models')
                    
                    pd.DataFrame({'feature_names': new_feature_names}).to_csv('models/feature_names.csv', index=False)
                    st.success(f"âœ… íŠ¹ì„± ì´ë¦„ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (íŠ¹ì„± ìˆ˜: {num_features}ê°œ)")
                
                # ëª¨ë¸ì— í•„ìš”í•œ ì •ë³´ ì €ì¥
                np.save('models/X_processed.npy', X_train_processed)
                
                # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ì €ì¥
                np.save('models/X_test.npy', X_test)
                np.save('models/y_test.npy', y_test)
                
                st.markdown(f"<div class='success-box'>âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ({best_model_name})ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!</div>", unsafe_allow_html=True)
                st.markdown(f"<div class='info-text'>ëª¨ë¸ ê²°ê³¼ê°€ 'ëª¨ë¸ í‰ê°€' í˜ì´ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    st.markdown("</div>", unsafe_allow_html=True)

# í•™ìŠµëœ ëª¨ë¸ ê²°ê³¼ ì„¹ì…˜ ì œê±° - ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œí•¨

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ì‚­ì œí•©ë‹ˆë‹¤. 